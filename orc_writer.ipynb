{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pyspark\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the write properties for spartk context\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '50g')\n",
    "SparkContext.setSystemProperty(\"spark.ui.port\", \"9800\")\n",
    "\n",
    "\n",
    "sc = SparkContext(\"local\", \"orc_writer\").getOrCreate()\n",
    "sql_sc = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '../../dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['nyt','tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_d = {}\n",
    "for dataset in datasets:\n",
    "    dataset_d[dataset] = [fn for fn in os.listdir(os.path.join(input_dir,dataset)) if '.csv' in fn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Write Files to orc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../../dataset/nyt/ArticlesFeb2017.csv\n",
      "Completed ../../dataset/nyt/orc/ArticlesFeb2017\n",
      "Completed ../../dataset/nyt/json/ArticlesFeb2017\n",
      "Completed ../../dataset/nyt/parquet/ArticlesFeb2017\n",
      "\n",
      "--------------------\n",
      "\n",
      "Reading ../../dataset/nyt/ArticlesMarch2017.csv\n",
      "Completed ../../dataset/nyt/orc/ArticlesMarch2017\n",
      "Completed ../../dataset/nyt/json/ArticlesMarch2017\n",
      "Completed ../../dataset/nyt/parquet/ArticlesMarch2017\n",
      "\n",
      "--------------------\n",
      "\n",
      "Reading ../../dataset/nyt/ArticlesJan2018.csv\n",
      "Completed ../../dataset/nyt/orc/ArticlesJan2018\n",
      "Completed ../../dataset/nyt/json/ArticlesJan2018\n",
      "Completed ../../dataset/nyt/parquet/ArticlesJan2018\n",
      "\n",
      "--------------------\n",
      "\n",
      "Reading ../../dataset/nyt/CommentsJan2017.csv\n",
      "Completed ../../dataset/nyt/orc/CommentsJan2017\n",
      "Completed ../../dataset/nyt/json/CommentsJan2017\n",
      "Completed ../../dataset/nyt/parquet/CommentsJan2017\n",
      "\n",
      "--------------------\n",
      "\n",
      "Reading ../../dataset/nyt/CommentsFeb2017.csv\n",
      "Completed ../../dataset/nyt/orc/CommentsFeb2017\n",
      "Completed ../../dataset/nyt/json/CommentsFeb2017\n",
      "Completed ../../dataset/nyt/parquet/CommentsFeb2017\n",
      "\n",
      "--------------------\n",
      "\n",
      "Reading ../../dataset/nyt/ArticlesApril2018.csv\n",
      "Completed ../../dataset/nyt/orc/ArticlesApril2018\n",
      "Completed ../../dataset/nyt/json/ArticlesApril2018\n",
      "Completed ../../dataset/nyt/parquet/ArticlesApril2018\n",
      "\n",
      "--------------------\n",
      "\n",
      "Reading ../../dataset/nyt/CommentsApril2018.csv\n",
      "Completed ../../dataset/nyt/orc/CommentsApril2018\n",
      "Completed ../../dataset/nyt/json/CommentsApril2018\n",
      "Completed ../../dataset/nyt/parquet/CommentsApril2018\n",
      "\n",
      "--------------------\n",
      "\n",
      "Reading ../../dataset/nyt/ArticlesMarch2018.csv\n",
      "Completed ../../dataset/nyt/orc/ArticlesMarch2018\n",
      "Completed ../../dataset/nyt/json/ArticlesMarch2018\n",
      "Completed ../../dataset/nyt/parquet/ArticlesMarch2018\n",
      "\n",
      "--------------------\n",
      "\n",
      "Reading ../../dataset/nyt/CommentsMay2017.csv\n",
      "Completed ../../dataset/nyt/orc/CommentsMay2017\n",
      "Completed ../../dataset/nyt/json/CommentsMay2017\n",
      "Completed ../../dataset/nyt/parquet/CommentsMay2017\n",
      "\n",
      "--------------------\n",
      "\n",
      "Reading ../../dataset/nyt/CommentsMarch2018.csv\n",
      "Completed ../../dataset/nyt/orc/CommentsMarch2018\n",
      "Completed ../../dataset/nyt/json/CommentsMarch2018\n",
      "Completed ../../dataset/nyt/parquet/CommentsMarch2018\n",
      "\n",
      "--------------------\n",
      "\n",
      "Reading ../../dataset/nyt/ArticlesFeb2018.csv\n",
      "Completed ../../dataset/nyt/orc/ArticlesFeb2018\n",
      "Completed ../../dataset/nyt/json/ArticlesFeb2018\n",
      "Completed ../../dataset/nyt/parquet/ArticlesFeb2018\n",
      "\n",
      "--------------------\n",
      "\n",
      "Reading ../../dataset/nyt/ArticlesJan2017.csv\n",
      "Completed ../../dataset/nyt/orc/ArticlesJan2017\n",
      "Completed ../../dataset/nyt/json/ArticlesJan2017\n",
      "Completed ../../dataset/nyt/parquet/ArticlesJan2017\n",
      "\n",
      "--------------------\n",
      "\n",
      "Reading ../../dataset/nyt/CommentsMarch2017.csv\n",
      "Completed ../../dataset/nyt/orc/CommentsMarch2017\n",
      "Completed ../../dataset/nyt/json/CommentsMarch2017\n",
      "Completed ../../dataset/nyt/parquet/CommentsMarch2017\n",
      "\n",
      "--------------------\n",
      "\n",
      "Reading ../../dataset/nyt/CommentsJan2018.csv\n",
      "Completed ../../dataset/nyt/orc/CommentsJan2018\n",
      "Completed ../../dataset/nyt/json/CommentsJan2018\n",
      "Completed ../../dataset/nyt/parquet/CommentsJan2018\n",
      "\n",
      "--------------------\n",
      "\n",
      "Reading ../../dataset/nyt/ArticlesApril2017.csv\n",
      "Completed ../../dataset/nyt/orc/ArticlesApril2017\n",
      "Completed ../../dataset/nyt/json/ArticlesApril2017\n",
      "Completed ../../dataset/nyt/parquet/ArticlesApril2017\n",
      "\n",
      "--------------------\n",
      "\n",
      "Reading ../../dataset/nyt/ArticlesMay2017.csv\n",
      "Completed ../../dataset/nyt/orc/ArticlesMay2017\n",
      "Completed ../../dataset/nyt/json/ArticlesMay2017\n",
      "Completed ../../dataset/nyt/parquet/ArticlesMay2017\n",
      "\n",
      "--------------------\n",
      "\n",
      "Reading ../../dataset/nyt/CommentsFeb2018.csv\n",
      "Completed ../../dataset/nyt/orc/CommentsFeb2018\n",
      "Completed ../../dataset/nyt/json/CommentsFeb2018\n",
      "Completed ../../dataset/nyt/parquet/CommentsFeb2018\n",
      "\n",
      "--------------------\n",
      "\n",
      "Reading ../../dataset/nyt/CommentsApril2017.csv\n",
      "Completed ../../dataset/nyt/orc/CommentsApril2017\n",
      "Completed ../../dataset/nyt/json/CommentsApril2017\n",
      "Completed ../../dataset/nyt/parquet/CommentsApril2017\n",
      "\n",
      "--------------------\n",
      "\n",
      "Reading ../../dataset/tweets/ira_tweets_csv_hashed.csv\n",
      "Completed ../../dataset/tweets/orc/ira_tweets_csv_hashed\n",
      "Completed ../../dataset/tweets/json/ira_tweets_csv_hashed\n",
      "Completed ../../dataset/tweets/parquet/ira_tweets_csv_hashed\n",
      "\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_dir,fn_ls in dataset_d.items():\n",
    "    for fn in fn_ls:\n",
    "        input_file_path = os.path.join(input_dir,dataset_dir,fn)        \n",
    "        # reading input file path\n",
    "        print(\"Reading {}\".format(input_file_path))\n",
    "        \n",
    "        df = sql_sc.read.csv(input_file_path, header='true',inferSchema='true')\n",
    "        \n",
    "        #write output to path:\n",
    "        output_dir = os.path.join(input_dir,dataset_dir)\n",
    "        output_file_path_orc = os.path.join(output_dir,'orc',fn[:-4])\n",
    "        output_file_path_json = os.path.join(output_dir,'json',fn[:-4])\n",
    "        output_file_path_parquet = os.path.join(output_dir,'parquet',fn[:-4])\n",
    "        \n",
    "        shutil.rmtree(output_file_path_orc, ignore_errors=True)   \n",
    "        shutil.rmtree(output_file_path_json, ignore_errors=True)   \n",
    "        shutil.rmtree(output_file_path_parquet, ignore_errors=True)   \n",
    "        \n",
    "        df.write.format(\"orc\").save(output_file_path_orc)\n",
    "        print(\"Completed {}\".format(output_file_path_orc))\n",
    "        \n",
    "        df.write.format(\"json\").save(output_file_path_json)\n",
    "        print(\"Completed {}\".format(output_file_path_json))\n",
    "\n",
    "        df.write.format(\"parquet\").save(output_file_path_parquet)\n",
    "        print(\"Completed {}\".format(output_file_path_parquet))\n",
    "        \n",
    "        print(\"\\n\"+\"--\"*10+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test written FIle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = '../../dataset/nyt/orc/CommentsApril2017'\n",
    "orc_df = sql_sc.read.orc(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[approveDate: string, commentBody: string, commentID: string, commentSequence: string, commentTitle: string, commentType: string, createDate: string, depth: string, editorsSelection: string, parentID: string, parentUserDisplayName: string, permID: string, picURL: string, recommendations: string, recommendedFlag: string, replyCount: string, reportAbuseFlag: string, sharing: string, status: string, timespeople: string, trusted: string, updateDate: string, userDisplayName: string, userID: string, userLocation: string, userTitle: string, userURL: string, inReplyTo: string, articleID: string, sectionName: string, newDesk: string, articleWordCount: string, printPage: string, typeOfMaterial: string]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"json\").save('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
